---
title: "TextPredict"
author: "Michael Pearson"
date: "9/3/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyr)
library(plyr)
```

## R Markdown

Get a prediction going

```{r read in the data files, eval = TRUE}
##  In this portion I read in the one_gram file, add column names and 
## turn it intoc a data table, and calculate the percentages of each word - one_gram

one_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/one_gram_ns_ns.csv")
colnames(one_grams) <- c("word1", "total")
one_grams <- data.table(one_grams)
one_grams$prob <- one_grams$total/sum(one_grams$total)

##In this I read in the bi_grams data, assign column names, convert it to a data table
## and get rid of the "X" column


bi_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_bi_ns_ns.csv")
colnames(bi_grams) <- c("X", "word1", "pred", "total", "prob")
bi_grams <- data.table(bi_grams)
bi_grams <- bi_grams[,2:5]

## Here we read the tri_grams data, assign column names, and convert to a data table 

tri_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_tri_ns_ns.csv")
tri_grams <- separate(tri_grams, bigrams, into = c("word1", "word2"), sep = " ")
colnames(tri_grams) <- c("X", "word1", "word2", "pred", "total", "prob")
tri_grams <- data.table(tri_grams)
tri_grams <- tri_grams[,2:6]

## Same deal with quad_grams, read the file, create column names, make a data table


quad_grams <-  read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quad.csv")
colnames(quad_grams) <- c("X", "word1", "word2","word3", "pred", "total", "prob")
quad_grams <- data.table(quad_grams)
quad_grams <- quad_grams[,2:7]

##quin_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quin.csv")
##colnames(quin_grams) <- c("X", "word1", "word2","word3", "word4", "pred","total", "prob")


## not sure if this is valuable, I will keep it for now

##n_grams <- rbind.fill(one_grams, bi_grams, tri_grams)
##n_grams <- data.table(n_grams)
##write.csv(n_grams, "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/n_grams.csv")

## just a practice problem for sorting with 'the first'
## since the minimum value set for the bigrams was 4 occurences, 
## I set the discount to 3.5


discount_bi <- 3.5
discount_tri <- 3.5


## find all trigrams that begin with the sample bigram "the first"
tri_grams <- data.table(tri_grams)
setkey(tri_grams, word1, word2)
triggy <- data.table(tri_grams[.("the", "first")])


## Use the discount_tri to get the new probs
total_trigs <- sum(triggy$total)
triggy$newprob <- (triggy$total - discount_tri)/total_trigs
gammatri <- 1 - sum(triggy$newprob)


## get all bigrams that start with the second word of the trigram
## let's do some backing off
## back off bigrams are made from the second word of the trigram
## Find all the bigrams that start with the second word
## exclude the predicted words already found in the trigram
## Find a discounted probability with the discount_tri
## 


tgramw2 <- data.table(triggy$pred)
setkey(bi_grams, word1)
tri_unused_bi_grams <- data.table(bi_grams["first"])
setkey(tri_unused_bi_grams, pred)
total_un_tri <- sum(tri_unused_bi_grams$total)
tri_unused_bi_grams <- tri_unused_bi_grams[!tgramw2]
tri_unused_bi_grams$newprob <- gammatri*(tri_unused_bi_grams$total - discount_tri)/total_un_tri
gammaone_g <- gammatri -  sum(tri_unused_bi_grams$newprob)



```

Count the words in the input - or just start with the first one
Get the whole n-gram
```{r separate input to column n-grams, include = TRUE}
##read input file clean up the dog
## get the input cleaned up keep only the last 3 words
make_it <- function(x){
x <- tolower(x)
x <- gsub("'ve", " have ", x) 
x <- gsub("'ll ", " will ", x) 
x <- gsub("'re ", " are ", x) 
x <- gsub("'d", " had ", x)
x <- gsub("i'm ", "i am ", x)
x <- gsub(" im ", "i am ", x)
x <- gsub("won't ", " will not ", x)
x <- gsub("n't ", " not ", x)
x <- gsub(" ur ", " your ", x)
x <- gsub("it's", "it is ", x)
x <- gsub("^ *|(?<= ) | *$", "", x, perl = TRUE)
x <- gsub("[^[:alpha:]]", " ", x) 
x <- data.table(x)
  trap <- separate(x, 1,into = c("word1", "word2", "word3","word4","word5", "word6", "word7"), sep = " ", extra = "merge", fill = "right")
is.na(trap) <- trap==''
clean_input <- as.vector(trap[,which(unlist(lapply(trap, function(x)!all(is.na(x))))),with=F])
word_num <- length(clean_input)
if (word_num == 7)
  {
  clean_input <- clean_input[1,5:7]
  colnames(clean_input) <- c("word1", "word2", "word3")
} 
else if (word_num == 6)
{
  clean_input <- clean_input[1,4:6]
  colnames(clean_input) <- c("word1", "word2", "word3")
}
else if (word_num == 5)
{
  clean_input <- clean_input[1,3:5]
  colnames(clean_input) <- c("word1", "word2", "word3")
}
else if (word_num == 4)
{
  clean_input <- clean_input[1,2:4]
  colnames(clean_input) <- c("word1", "word2", "word3")
}
return(clean_input)
}
### clean_input is the cleaned up input, with "word1" being the left-most word and
## "word2" next and "word3" at the end
## use "word2" and "word3" for trigrams
## use "word3 for bigrams"



setkey(n_grams, word1)
try1 <- n_grams[out$word4]
try1 <- try1[is.na(try1$word2),]
try1$weighted <- try1[,.(prob*0.4)]
setkey(n_grams, word1, word2)
try2 <- n_grams[.(out$word3, out$word4)]
try2 <- try2[is.na(try2$word3),]
try2$weighted <- try2[,.(prob*0.5)]
setkey(n_grams, word1, word2, word3)
try3 <- n_grams[.(out$word2, out$word3, out$word4)]
try3 <- try3[is.na(try3$word4),]
try3$weighted <- try3[,.(prob*0.6)]
setkey(n_grams, word1, word2, word3, word4)
try4 <- n_grams[.(out$word1, out$word2, out$word3, out$word4)]
try4$weighted <- try4[,.(prob*1.0)]
newt <- rbind(try4, try3, try2, try1)
newt <- data.table(newt)
newt <- newt[order(-weighted),]
newt <- newt[1:3,5]
newt<- data.frame(lapply(newt, as.character), stringsAsFactors = FALSE)
nearly <- c(newt[1,1],newt[2,1],newt[3,1])
if (sum(is.na(nearly) == 1))
  {
  nearly <- c("the","on","a")
  }
else if (sum(is.na(nearly) == 2)){
nearly <- c("the","on","a")
}
else if (sum(is.na(nearly) == 3)){
nearly <- c("the","on","a")
}
else {nearly <- c(newt[1,1],newt[2,1],newt[3,1])}
return(nearly)
}

```

## The part where a choice is made

```{r pressure, echo=FALSE}
tweet_us <- file("/Users/mutecypher/Documents/Coursera/Capstone Project/files/en_US/en_US.twitter.txt")
tweets <- readLines(tweet_us, encoding = 'UTF-8', warn = FALSE)
out <- make_it(tweets[9])
setkey(n_grams, word1)
try1 <- n_grams[out$word4]
try1 <- try1[is.na(try1$word2),]
try1$weighted <- try1[,.(prob*0.4)]
setkey(n_grams, word1, word2)
try2 <- n_grams[.(out$word3, out$word4)]
try2 <- try2[is.na(try2$word3),]
try2$weighted <- try2[,.(prob*0.5)]
setkey(n_grams, word1, word2, word3)
try3 <- n_grams[.(out$word2, out$word3, out$word4)]
try3 <- try3[is.na(try3$word4),]
try3$weighted <- try3[,.(prob*0.6)]
setkey(n_grams, word1, word2, word3, word4)
try4 <- n_grams[.(out$word1, out$word2, out$word3, out$word4)]
try4$weighted <- try4[,.(prob*1.0)]
newt <- rbind(try4, try3, try2, try1)
newt <- newt[order(-weighted),]
result <- newt[1:3,5]

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
