---
title: "Looking_for_it"
author: "Michael Pearson"
date: "7/23/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyr)
library(plyr)
```

## R Markdown

Get a prediction going

```{r read in the data files, eval = TRUE}
##  In this portion I read in the one_gram file, add column names and 
## turn it intoc a data table, and calculate the percentages of each word - one_gram

one_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/one_gram_ns_ns.csv")
colnames(one_grams) <- c("word1", "total")
one_grams <- data.table(one_grams)
one_grams$prob <- one_grams$total/sum(one_grams$total)

##In this I read in the bi_grams data, assign column names, convert it to a data table
## and get rid of the "X" column


bi_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_bi_ns_ns.csv")
colnames(bi_grams) <- c("X", "word1", "pred", "total", "prob")
bi_grams <- data.table(bi_grams)
bi_grams <- bi_grams[,2:5]

## Here we read the tri_grams data, assign column names, and convert to a data table 

tri_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_tri_ns_ns.csv")
tri_grams <- separate(tri_grams, bigrams, into = c("word1", "word2"), sep = " ")
colnames(tri_grams) <- c("X", "word1", "word2", "pred", "total", "prob")
tri_grams <- data.table(tri_grams)
tri_grams <- tri_grams[,2:6]

## Same deal with quad_grams, read the file, create column names, make a data table


quad_grams <-  read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quad.csv")
colnames(quad_grams) <- c("X", "word1", "word2","word3", "pred", "total", "prob")
quad_grams <- data.table(quad_grams)
quad_grams <- quad_grams[,2:7]

##quin_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quin.csv")
##colnames(quin_grams) <- c("X", "word1", "word2","word3", "word4", "pred","total", "prob")


## not sure if this is valuable, I will keep it for now

##n_grams <- rbind.fill(one_grams, bi_grams, tri_grams)
##n_grams <- data.table(n_grams)
##write.csv(n_grams, "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/n_grams.csv")

## just a practice problem for sorting with 'the first'
## since the minimum value set for the bigrams was 4 occurences, 
## I set the discount to 3.5


discount_bi <- 3.5
discount_tri <- 3.5


## find all trigrams that begin with the sample bigram "the first"
tri_grams <- data.table(tri_grams)
setkey(tri_grams, word1, word2)
triggy <- data.table(tri_grams[.("the", "first")])


## Use the discount_tri to get the new probs
total_trigs <- sum(triggy$total)
triggy$newprob <- (triggy$total - discount_tri)/total_trigs
gammatri <- 1 - sum(triggy$newprob)


## get all bigrams that start with the second word of the trigram
## let's do some backing off
## back off bigrams are made from the second word of the trigram
## Find all the bigrams that start with the second word
## exclude the predicted words already found in the trigram
## Find a discounted probability with the discount_tri
## 


tgramw2 <- data.table(triggy$pred)
setkey(bi_grams, word1)
tri_unused_bi_grams <- data.table(bi_grams["first"])
setkey(tri_unused_bi_grams, pred)
total_un_tri <- sum(tri_unused_bi_grams$total)
tri_unused_bi_grams <- tri_unused_bi_grams[!tgramw2]
tri_unused_bi_grams$newprob <- gammatri*(tri_unused_bi_grams$total - discount_tri)/total_un_tri
gammaone_g <- gammatri -  sum(tri_unused_bi_grams$newprob)


## the probability mass discount is the 1 minus the newprob
## this will be used once we find the back off bigrams - the unobserved ones
alpha_tri <- 1 - (sum(triggy$newprob))
## get the back off bigrams
## start with the second word of the trigram, and get all the unobserved unigrams
## from the trigram
setkey(bi_grams, word1)
biggy <- bi_grams["first"]
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
## remove NAs
backoff_bigrams <- backoff_bigrams[complete.cases(backoff_bigrams)]
backoff_bigrams <- backoff_bigrams[,1:4]
## find the observed backoff bigrams and their probabilities
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams$word1)]
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(tri_unused_one_grams$total)
## now find the unobserved backoff bigrams and their probabilities
## Probability of the unobserved back off bigrams is alpha 1( 1 minus the ratio of 
##the sum of all bigrams starting with word 2 divided by the count of the unigram of ##word 2) times (count of each unobserved unigram minus discount) divided by the sum ##of all unobserved trig tail unigrams
alpha1 <- 1 - (sum(biggy$total)/(one_grams["first"]$total))
unobs_backoff_bigrams <- data.table("first", tri_unused_one_grams)
colnames(unobs_backoff_bigrams) <- c("word1", "pred", "total", "prob")
unobs_backoff_bigrams$newprob <- alpha1 * (unobs_backoff_bigrams$total - discount_bi)/sum(unobs_backoff_bigrams$total)
## now find the probability of the unobserved trigrams
## make unobserved trigrams by appending the unobserved tail words to the bigram
setkey(tri_grams, word1, word2, pred)
unobserved_tri_grams <- data.table("first","the", tri_unused_one_grams)
colnames(unobserved_tri_grams) <- c("word1","word2", "pred", "total", "prob")
## now calculate alpha2, the trigram alpha
alpha2 <- 1 - sum(triggy$total - discount_tri)/sum(triggy$total)
## now the probs of the unobserved trigrams alpha2 times unobserved trigrams divided
## by sum of the observed trigrams prob
unobserved_tri_grams$newprob <- alpha2*unobserved_tri_grams$prob/sum(triggy$newprob)
this_is_it <- rbind.fill(triggy, unobserved_tri_grams)



```

Count the words in the input - or just start with the first one
Get the whole n-gram
```{r separate input to column n-grams, include = TRUE}
##read input file
make_it <- function(x){
x <- tolower(x)
x <- gsub("'ve ", " have ", x) 
x <- gsub("'ll ", " will ", x) 
x <- gsub("'re ", " are ", x) 
x <- gsub("'d ", " had ", x)
x <- gsub(" i'm ", "i am ", x)
x <- gsub(" im ", "i am ", x)
x <- gsub(" won't ", " will not ", x)
x <- gsub("n't ", " not ", x)
x <- gsub(" ur ", " your ", x)
x <- gsub("it's ", "it is ", x)
x <- gsub("^ *|(?<= ) | *$", "", x, perl = TRUE)
x <- gsub("[^[:alpha:]]", " ", x) 
x <- data.table(x)
  trap <- separate(x, 1,into = c("word1", "word2", "word3","word4"), sep = " ", extra = "drop", fill = "right")
is.na(trap) <- trap==''
out <- trap
setkey(n_grams, word1)
try1 <- n_grams[out$word4]
try1 <- try1[is.na(try1$word2),]
try1$weighted <- try1[,.(prob*0.4)]
setkey(n_grams, word1, word2)
try2 <- n_grams[.(out$word3, out$word4)]
try2 <- try2[is.na(try2$word3),]
try2$weighted <- try2[,.(prob*0.5)]
setkey(n_grams, word1, word2, word3)
try3 <- n_grams[.(out$word2, out$word3, out$word4)]
try3 <- try3[is.na(try3$word4),]
try3$weighted <- try3[,.(prob*0.6)]
setkey(n_grams, word1, word2, word3, word4)
try4 <- n_grams[.(out$word1, out$word2, out$word3, out$word4)]
try4$weighted <- try4[,.(prob*1.0)]
newt <- rbind(try4, try3, try2, try1)
newt <- data.table(newt)
newt <- newt[order(-weighted),]
newt <- newt[1:3,5]
newt<- data.frame(lapply(newt, as.character), stringsAsFactors = FALSE)
nearly <- c(newt[1,1],newt[2,1],newt[3,1])
if (sum(is.na(nearly) == 1))
  {
  nearly <- c("the","on","a")
  }
else if (sum(is.na(nearly) == 2)){
nearly <- c("the","on","a")
}
else if (sum(is.na(nearly) == 3)){
nearly <- c("the","on","a")
}
else {nearly <- c(newt[1,1],newt[2,1],newt[3,1])}
return(nearly)
}

```

## The part where a choice is made

```{r pressure, echo=FALSE}
tweet_us <- file("/Users/mutecypher/Documents/Coursera/Capstone Project/files/en_US/en_US.twitter.txt")
tweets <- readLines(tweet_us, encoding = 'UTF-8', warn = FALSE)
out <- make_it(tweets[9])
setkey(n_grams, word1)
try1 <- n_grams[out$word4]
try1 <- try1[is.na(try1$word2),]
try1$weighted <- try1[,.(prob*0.4)]
setkey(n_grams, word1, word2)
try2 <- n_grams[.(out$word3, out$word4)]
try2 <- try2[is.na(try2$word3),]
try2$weighted <- try2[,.(prob*0.5)]
setkey(n_grams, word1, word2, word3)
try3 <- n_grams[.(out$word2, out$word3, out$word4)]
try3 <- try3[is.na(try3$word4),]
try3$weighted <- try3[,.(prob*0.6)]
setkey(n_grams, word1, word2, word3, word4)
try4 <- n_grams[.(out$word1, out$word2, out$word3, out$word4)]
try4$weighted <- try4[,.(prob*1.0)]
newt <- rbind(try4, try3, try2, try1)
newt <- newt[order(-weighted),]
result <- newt[1:3,5]

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
