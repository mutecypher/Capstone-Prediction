##            prefix we are attempting to the predict the next word of. The
##            second column: freq, contains the frequency/count of each trigram.
## bigram - single row frequency table where the first col: ngram, is the bigram
##          which are the first two words of unobserved trigrams we want to
##          estimate probabilities of (same as bigPre in other functions listed
##          prior) delimited with '_'. The second column: freq, is the
##          frequency/count of the bigram listed in the ngram column.
## triDisc - amount to discount observed trigrams
getAlphaTrigram <- function(obsTrigs, bigram, triDisc=0.5) {
if(nrow(obsTrigs) < 1) return(1)
alphaTri <- 1 - sum((obsTrigs$freq - triDisc) / bigram$freq[1])
return(alphaTri)
}
bigram <- bigrs[bigrs$ngram %in% bigPre, ]
alpha_trig <- getAlphaTrigram(obs_trigs, bigram, gamma3)
alpha_trig
head(bigram)
trigs
1 - (0.5/9 + 0.5/9)/(2/9)
alpha_tri <- 1 - (sum(triggy$newprob))
alpha_tri
head(triggy)
alpha_tri <- 1 - (sum(triggy$total - 0.5))/sum(triggy$total)
alpha_tri
## Returns a dataframe of 2 columns: ngram and prob.  Values in the ngram
## column are unobserved trigrams of the form: w3_w2_w1.  The values in the prob
## column are q_bo(w1 | w3, w2) calculated from equation 17.
##
## bigPre -  single-element char array of the form w2_w1 which are first two
##           words of the trigram we are predicting the tail word of
## qboObsBigrams - 2 column data.frame with the following columns -
##                 ngram: observed bigrams of the form w2_w1
##                 probs: the probability estimate for observed bigrams:
##                        qbo(w1 | w2) calc'd from equation 10.
## qboUnobsBigrams - 2 column data.frame with the following columns -
##                   ngram: unobserved bigrams of the form w2_w1
##                   probs: the probability estimate for unobserved bigrams
##                          qbo(w1 | w2) calc'd from equation 16.
## alphaTrig - total discounted probability mass at the trigram level
getUnobsTriProbs <- function(bigPre, qboObsBigrams,
qboUnobsBigrams, alphaTrig) {
qboBigrams <- rbind(qboObsBigrams, qboUnobsBigrams)
qboBigrams <- qboBigrams[order(-qboBigrams$prob), ]
sumQboBigs <- sum(qboBigrams$prob)
first_bigPre_word <- str_split(bigPre, "_")[[1]][1]
unobsTrigNgrams <- paste(first_bigPre_word, qboBigrams$ngram, sep="_")
unobsTrigProbs <- alphaTrig * qboBigrams$prob / sumQboBigs
unobsTrigDf <- data.frame(ngram=unobsTrigNgrams, prob=unobsTrigProbs)
return(unobsTrigDf)
}
qbo_unobs_trigrams <- getUnobsTriProbs(bigPre, qbo_obs_bigrams,
qbo_unobs_bigrams, alpha_trig)
qbo_unobs_trigrams
qboBigrams <- rbind(qbo_obs_bigrams, qbo_unobs_bigrams)
qboBigrams
qboBigrams <- qboBigrams[order(-qboBigrams$prob), ]
qboBigrams
sumQboBigs <- sum(qboBigrams$prob)
sumQboBigs
first_bigPre_word <- str_split(bigPre, "_")[[1]][1]
first_bigPre_word
unobsTrigNgrams <- paste(first_bigPre_word, qboBigrams$ngram, sep="_")
unobsTrigNgrams
one_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/one_gram_ns_ns.csv")
colnames(one_grams) <- c("word1", "total")
one_grams <- data.table(one_grams)
one_grams$prob <- one_grams$total/sum(one_grams$total)
bi_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_bi_ns_ns.csv")
colnames(bi_grams) <- c("X", "word1", "pred", "total", "prob")
bi_grams <- data.table(bi_grams)
tri_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_tri_ns_ns.csv")
tri_grams <- separate(tri_grams, bigrams, into = c("word1", "word2"), sep = " ")
colnames(tri_grams) <- c("X", "word1", "word2", "pred", "total", "prob")
##quad_grams <-  read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quad.csv")
##colnames(quad_grams) <- c("X", "word1", "word2","word3", "pred", "total", "prob")
##quin_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quin.csv")
##colnames(quin_grams) <- c("X", "word1", "word2","word3", "word4", "pred","total", "prob")
n_grams <- rbind.fill(one_grams, bi_grams, tri_grams)
n_grams <- n_grams[c(1,2,6,3,4,5)]
n_grams <- n_grams[,2:6]
n_grams <- data.table(n_grams)
write.csv(n_grams, "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/n_grams.csv")
setkey(bi_grams, word1)
## just a practice problem for sorting with 'the first'
discount_bi <- 0.5
discount_tri <- 0.5
## find all trigrams that begin with the sample bigram "the first"
tri_grams <- data.table(tri_grams)
setkey(tri_grams, word1, word2)
triggy <- data.table(tri_grams[.("the", "first")])
triggy <- triggy[,c(2:6)]
## and the discounted probs
triggy$newprob <- (triggy$total - discount_tri)/(sum(triggy$total))
## get all bigrams that start with the second word of the trigram
## let's do some backing off
## back off bigrams are made from the second word of the trigram
## and the unigrams of all the unobserved ending words of the trigrams
## get a list of all the unobserved trigram endings
tgramw2 <- data.table(triggy$pred)
setkey(one_grams, word1)
tri_unused_one_grams <- data.table(one_grams[!tgramw2])
## the probability mass discount is the 1 minus the newprob
## this will be used once we find the back off bigrams - the unobserved ones
alpha_tri <- 1 - (sum(triggy$newprob))
## get the back off bigrams
## start with the second word of the trigram, and get all the unobserved unigrams
## from the trigram
biggy <- bi_grams["first"]
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
head(backoff_bigrams)
tail(backoff_bigrams)
backoff_bigrams <- backoff_bigrams[order(word1)]
tail(backoff_bigrams)
head(backoff_bigrams)
head(biggy)
tail(biggy)
biggy <- bi_grams["first"]
head(biggy)
tail(biggy)
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
head(biggy)
tail(biggy)
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
dim(biggy)
dim(backoff_bigrams)
backoff_bigrams <- backoff_bigrams(complete.cases(backoff_bigrams))
backoff_bigramz <- backoff_bigrams[complete.cases(backoff_bigrams)]
dim(backoff_bigramz)
head(backoff_bigramz)
tail(backoff_bigramz)
tail(biggy)
sum(backoff_bigrams$prob)
head(backoff_bigrams)
biggy <- bi_grams["first"]
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
## remove NAs
backoff_bigrams <- backoff_bigrams[complete.cases(backoff_bigrams)]
head(backoff_bigrams)
head(biggy)
sum(biggy$prob)
biggy <- bi_grams["first"]
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
## remove NAs
backoff_bigrams <- backoff_bigrams[complete.cases(backoff_bigrams)]
backoff_bigrams <- backoff_bigrams[,1:4]
head(backoff_bigrams)
sum(backoff_bigrams$prob)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.,("first", tri_unused_one_grams)]
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams)]
obs_backoff_bigrams
dim(obs_backoff_bigrams)
head(bi_grams)
obs_backoff_bigrams
setkey(bi_grams, word1)
obs_backoff_bigrams <- bi_grams["first"]
obs_backoff_bigrams <- data.table(bi_grams["first"])
setkey(obs_backoff_bigrams, pred)
obs_backoff_bigrams <- obs_backoff_bigrams[tri_unused_one_grams]
dim(obs_backoff_bigrams)
setkey(bi_grams, word1)
obs_backoff_bigrams <- bi_grams["first"]
dim(obs_backoff_bigrams)
setkey(obs_backoff_bigrams, pred)
obs_backoff_bigrams <- obs_backoff_bigrams[tri_unused_one_grams]
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
dim(obs_backoff_bigrams)
head(obs_backoff_bigrams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- data.table(.(bi_grams["first"], tri_unused_one_grams))
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
head(obs_backoff_bigrams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- data.table(.(bi_grams["first", tri_unused_one_grams]))
head(obs_backoff_bigrams)
obs_backoff_bigrams <- data.table((bi_grams["first", tri_unused_one_grams]))
obs_backoff_bigrams <- data.table(bi_grams["first", tri_unused_one_grams])
obs_backoff_bigrams <- data.table(bi_grams[.("first", tri_unused_one_grams)])
dim(obs_backoff_bigrams)
head(backoff_bigrams)
head(obs_backoff_bigrams)
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
dim(obs_backoff_bigrams)
head(obs_backoff_bigrams)
head(backoff_bigrams)
sum(backoff_bigrams$prob)
min(backoff_bigrams$total)
head(tri_unused_one_grams)
tail(tri_unused_one_grams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams)]
head(obs_backoff_bigrams)
head(tri_unused_one_grams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams$word1)]
dim(obs_backoff_bigrams)
head(obs_backoff_bigrams)
tail(obs_backoff_bigrams)
trick <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
dim(trick)
head(trick)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(obs_backoff_bigrams$total)
head(obs_backoff_bigrams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(obs_backoff_bigrams$total)
head(obs_backoff_bigrams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams$word1)]
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(obs_backoff_bigrams$total)
head(obs_backoff_bigrams)
head(biggy)
alpha1 <- 1 - (sum(biggy$prob)/(one_grams$total["first"]))
alpha1
one_grams["first"]
one_grams["first"]$total
alpha1 <- 1 - (sum(biggy$prob)/(one_grams["first"]$total))
alpha1
alpha1 <- 1 - (sum(biggy$total)/(one_grams["first"]$total))
alpha1
unobs_backoff_bigrams <- data.table("first", tri_unused_one_grams)
dim(unobs_backoff_bigrams)
head(unobs_backoff_bigrams)
colnames(unobs_backoff_bigrams) <- c("word1", "pred", "total", "prob")
head(unobs_backoff_bigrams)
tail(unobs_backoff_bigrams)
max(unobs_backoff_bigrams$total)
unobs_backoff_bigrams$newprob <- alpha1 * (unobs_backoff_bigrams$total - discount_bi)/sum(unobs_backoff_bigrams$total)
head(unobs_backoff_bigrams)
max(unobs_backoff_bigrams$prob)
max(unobs_backoff_bigrams$newprob)
sum(unobs_backoff_bigrams$newprob)
unobserved_tri_grams <- data.table(c("first", "the", unused_one_grams))
dim(unobserved_tri_grams)
unobserved_tri_grams <- data.table(c("first", "the", tri_unused_one_grams))
dim(unobserved_tri_grams)
unobserved_tri_grams
setkey(tri_grams, word1, word2, pred)
unobserved_tri_grams <- data.table(tri_grams[.("first","the", tri_unused_one_grams)])
head(unobserved_tri_grams)
unobserved_tri_grams <- data.table("first","the", tri_unused_one_grams)
head(unobserved_tri_grams)
colnames(unobserved_tri_grams) <- c("word1","word2", "pred", "total", "prob")
head(unobserved_tri_grams)
alpha2 <- 1 - (sum(triggy$total - discount_tri)/sum(triggy$total))
alpha2
unobserved_tri_grams$newprob <- alpha2 * unobserved_tri_grams$prob/sum(triggy$prob)
head(unobserved_tri_grams)
one_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/one_gram_ns_ns.csv")
colnames(one_grams) <- c("word1", "total")
one_grams <- data.table(one_grams)
one_grams$prob <- one_grams$total/sum(one_grams$total)
bi_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_bi_ns_ns.csv")
colnames(bi_grams) <- c("X", "word1", "pred", "total", "prob")
bi_grams <- data.table(bi_grams)
tri_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_tri_ns_ns.csv")
tri_grams <- separate(tri_grams, bigrams, into = c("word1", "word2"), sep = " ")
colnames(tri_grams) <- c("X", "word1", "word2", "pred", "total", "prob")
##quad_grams <-  read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quad.csv")
##colnames(quad_grams) <- c("X", "word1", "word2","word3", "pred", "total", "prob")
##quin_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/sep_quin.csv")
##colnames(quin_grams) <- c("X", "word1", "word2","word3", "word4", "pred","total", "prob")
n_grams <- rbind.fill(one_grams, bi_grams, tri_grams)
n_grams <- n_grams[c(1,2,6,3,4,5)]
n_grams <- n_grams[,2:6]
n_grams <- data.table(n_grams)
write.csv(n_grams, "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/n_grams.csv")
## just a practice problem for sorting with 'the first'
discount_bi <- 0.5
discount_tri <- 0.5
## find all trigrams that begin with the sample bigram "the first"
tri_grams <- data.table(tri_grams)
setkey(tri_grams, word1, word2)
triggy <- data.table(tri_grams[.("the", "first")])
triggy <- triggy[,c(2:6)]
## and the discounted probs
triggy$newprob <- (triggy$total - discount_tri)/(sum(triggy$total))
## get all bigrams that start with the second word of the trigram
## let's do some backing off
## back off bigrams are made from the second word of the trigram
## and the unigrams of all the unobserved ending words of the trigrams
## get a list of all the unobserved trigram endings
tgramw2 <- data.table(triggy$pred)
setkey(one_grams, word1)
tri_unused_one_grams <- data.table(one_grams[!tgramw2])
## the probability mass discount is the 1 minus the newprob
## this will be used once we find the back off bigrams - the unobserved ones
alpha_tri <- 1 - (sum(triggy$newprob))
## get the back off bigrams
## start with the second word of the trigram, and get all the unobserved unigrams
## from the trigram
setkey(bi_grams, word1)
biggy <- bi_grams["first"]
biggy <- data.table(biggy)
biggy <- biggy[,c(2:5)]
setkey(biggy, pred)
backoff_bigrams <- data.table(biggy[tri_unused_one_grams])
## remove NAs
backoff_bigrams <- backoff_bigrams[complete.cases(backoff_bigrams)]
backoff_bigrams <- backoff_bigrams[,1:4]
## find the observed backoff bigrams and their probabilities
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams$word1)]
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(obs_backoff_bigrams$total)
## now find the unobserved backoff bigrams and their probabilities
## Probability of the unobserved back off bigrams is alpha 1( 1 minus the ratio of
##the sum of all bigrams starting with word 2 divided by the count of the unigram of ##word 2) times (count of each unobserved unigram minus discount) divided by the sum ##of all unobserved trig tail unigrams
alpha1 <- 1 - (sum(biggy$total)/(one_grams["first"]$total))
unobs_backoff_bigrams <- data.table("first", tri_unused_one_grams)
colnames(unobs_backoff_bigrams) <- c("word1", "pred", "total", "prob")
unobs_backoff_bigrams$newprob <- alpha1 * (unobs_backoff_bigrams$total - discount_bi)/sum(unobs_backoff_bigrams$total)
## now find the probability of the unobserved trigrams
## make unobserved trigrams by appending the unobserved tail words to the bigram
setkey(tri_grams, word1, word2, pred)
unobserved_tri_grams <- data.table("first","the", tri_unused_one_grams)
colnames(unobserved_tri_grams) <- c("word1","word2", "pred", "total", "prob")
## now calculate alpha2, the trigram alpha
alpha2 <- 1 - (sum(triggy$total - discount_tri)/sum(triggy$total))
## now the probs of the unobserved trigrams alpha2 times unobserved trigrams divided
## by sum of the observed trigrams prob
unobserved_tri_grams$newprob <- alpha2 * unobserved_tri_grams$prob/sum(triggy$prob)
head(triggy)
sum(triggy$newprob)
sum(unobs_backoff_bigrams$newprob)
sum(unobserved_tri_grams$newprob)
sum(obs_backoff_bigrams$newprob)
dim(obs_backoff_bigrams)
head(obs_backoff_bigrams)
max(obs_backoff_bigrams$newprob)
.02*200
dim(backoff_bigrams)
setkey(bi_grams, word1, pred)
obs_backoff_bigrams <- bi_grams[.("first", tri_unused_one_grams$word1)]
head(obs_backoff_bigrams)
dim(obs_backoff_bigrams)
obs_backoff_bigrams <- obs_backoff_bigrams[complete.cases(obs_backoff_bigrams)]
dim(obs_backoff_bigrams)
head(obs_backoff_bigrams)
sum(obs_backoff_bigrams$prob)
obs_backoff_bigrams$newprob <- (obs_backoff_bigrams$total - discount_bi)/sum(tri_unused_one_grams$total)
sum(obs_backoff_bigrams$newprob)
sum(unobs_backoff_bigrams)
sum(unobs_backoff_bigrams$newprob)
dim(unobs_backoff_bigrams)
dim(obs_backoff_bigrams)
sum(unobs_backoff_bigrams$newprob) + sum(unobserved_tri_grams$newprob) + sum(obs_backoff_bigrams$newprob) + sum(triggy$newprob)
sum(unobs_backoff_bigrams$newprob) + sum(unobserved_tri_grams$newprob) + sum(obs_backoff_bigrams$newprob)
triggy$newprob <- (triggy$total - discount_tri)/(sum(triggy$total))
dim(triggy)
head(triggy)
sum(triggy$prob)
head(tri_grams)
tri_grams <- read.csv( "/Users/mutecypher/Documents/Coursera/Capstone Project/20sample/nosingles_tri_ns_ns.csv")
head(tri_grams)
tri_grams <- separate(tri_grams, bigrams, into = c("word1", "word2"), sep = " ")
head(tri_grams)
colnames(tri_grams) <- c("X", "word1", "word2", "pred", "total", "prob")
head(tri_grams)
tri_grams <- data.table(tri_grams)
setkey(tri_grams, word1, word2)
triggy <- data.table(tri_grams[.("the", "first")])
dim(triggy)
head(triggy)
sum(tri_grams[tri_grams$word1 == "the"]$prob)
sum(tri_grams[tri_grams$word1 == "the", tri_grams$word2 == "first"]$prob)
sum(tri_grams[tri_grams$word1 == "the" && tri_grams$word2 == "first"]$prob)
sum(tri_grams[tri_grams$word1 == "the" & tri_grams$word2 == "first"]$prob)
trappy <- tri_grams[tri_grams$word1 == "the" & tri_grams$word2 == "first"]
head9trappy
head(trappy)
head(triggy)
115/sum(triggy$total)
1 - 105/sum(triggy$total)
triggy$newprob <- (triggy$total - discount_tri)/sum(triggy$total)
sum(triggy$newprob)
sum(triggy$newprob) + sum(unobserved_tri_grams$newprob)
tail(triggy)
this_is_it <- rbind.fill(triggy, unobserved_tri_grams)
head(this_is_it)
this_is_it <- this_is_it[order(this_is_it$newprob)]
this_is_it <- this_is_it[order(this_is_it$newprob),]
head(this_is_it)
this_is_it <- this_is_it[-order(this_is_it$newprob),]
head(this_is_it)
this_is_it <- this_is_it[order(this_is_it$newprob),]
tail(this_is_it)
this_is_it <- rbind.fill(triggy, unobserved_tri_grams)
heaD(this_is_it)
head(this_is_it)
this_is_it <- this_is_it[order(this_is_it$newprob),]
head(this_is_it)
tail(this_is_it)
?order
this_is_it <- this_is_it[order(this_is_it$newprob, decreasing = TRUE),]
head(this_is_it)
sum(this_is_it$newprob)
alpha2 <- 1 - sum(triggy$total - discount_tri)/sum(triggy$total)
alpha2
unobserved_tri_grams$newprob <- alpha2 * unobserved_tri_grams$prob/sum(triggy$newprob)
this_is_it <- rbind.fill(triggy, unobserved_tri_grams)
sum(this_is_it$newprob)
dim(tri_unused_one_grams)
dim(triggy)
dim(tri_grams)
tgramw2
dim(one_grams)
gamma2 <- 0.5  # bigram discount
gamma3 <- 0.5  # trigram discount
bigPre <- 'sell_the'
getObsTrigs <- function(bigPre, trigrams) {
trigs.winA <- data.frame(ngrams=vector(mode = 'character', length = 0),
freq=vector(mode = 'integer', length = 0))
regex <- sprintf("%s%s%s", "^", bigPre, "_")
trigram_indices <- grep(regex, trigrams$ngram)
if(length(trigram_indices) > 0) {
trigs.winA <- trigrams[trigram_indices, ]
}
return(trigs.winA)
}
getObsTriProbs <- function(obsTrigs, bigrs, bigPre, triDisc=0.5) {
if(nrow(obsTrigs) < 1) return(NULL)
obsCount <- filter(bigrs, ngram==bigPre)$freq[1]
obsTrigProbs <- mutate(obsTrigs, freq=((freq - triDisc) / obsCount))
colnames(obsTrigProbs) <- c("ngram", "prob")
return(obsTrigProbs)
}
obs_trigs <- getObsTrigs(bigPre, trigs)  # get trigrams and counts
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(quanteda)
library(dplyr)
library(stringr)
ltcorpus <- readLines("little_test_corpus1.txt")
ltcorpus
getNgramFreqs <- function(ng, dat, ignores=NULL,
sort.by.ngram=TRUE, sort.by.freq=FALSE) {
# http://stackoverflow.com/questions/36629329/
# how-do-i-keep-intra-word-periods-in-unigrams-r-quanteda
if(is.null(ignores)) {
dat.dfm <- dfm(dat, ngrams=ng, toLower = FALSE, removePunct = FALSE,
what = "fasterword", verbose = FALSE)
} else {
dat.dfm <- dfm(dat, ngrams=ng, toLower = FALSE, ignoredFeatures=ignores,
removePunct = FALSE, what = "fasterword", verbose = FALSE)
}
rm(dat)
# quanteda docfreq will get the document frequency of terms in the dfm
ngram.freq <- docfreq(dat.dfm)
if(sort.by.freq) { ngram.freq <- sort(ngram.freq, decreasing=TRUE) }
if(sort.by.ngram) { ngram.freq <- ngram.freq[sort(names(ngram.freq))] }
rm(dat.dfm)
return(ngram.freq)
}
getNgramTables <- function(ng, linesCorpus, prefixFilter=NULL) {
ngrams <- getNgramFreqs(ng, linesCorpus)
ngrams_dt <- data.table(ngram=names(ngrams), freq=ngrams)
if(length(grep('^SOS', ngrams_dt$ngram)) > 0) {
ngrams_dt <- ngrams_dt[-grep('^SOS', ngrams_dt$ngram),]
}
if(!is.null(prefixFilter)) {
regex <- sprintf('%s%s', '^', prefixFilter)
ngrams_dt <- ngrams_dt[grep(regex, ngrams_dt$ngram),]
}
return(ngrams_dt)
}
unigs <- getNgramTables(1, ltcorpus)
bigrs <- getNgramTables(2, ltcorpus)
trigs <- getNgramTables(3, ltcorpus)
unigs; bigrs; trigs
gamma2 <- 0.5  # bigram discount
gamma3 <- 0.5  # trigram discount
bigPre <- 'sell_the'
getObsTrigs <- function(bigPre, trigrams) {
trigs.winA <- data.frame(ngrams=vector(mode = 'character', length = 0),
freq=vector(mode = 'integer', length = 0))
regex <- sprintf("%s%s%s", "^", bigPre, "_")
trigram_indices <- grep(regex, trigrams$ngram)
if(length(trigram_indices) > 0) {
trigs.winA <- trigrams[trigram_indices, ]
}
return(trigs.winA)
}
getObsTriProbs <- function(obsTrigs, bigrs, bigPre, triDisc=0.5) {
if(nrow(obsTrigs) < 1) return(NULL)
obsCount <- filter(bigrs, ngram==bigPre)$freq[1]
obsTrigProbs <- mutate(obsTrigs, freq=((freq - triDisc) / obsCount))
colnames(obsTrigProbs) <- c("ngram", "prob")
return(obsTrigProbs)
}
obs_trigs <- getObsTrigs(bigPre, trigs)  # get trigrams and counts
# convert counts to probabilities
qbo_obs_trigrams <- getObsTriProbs(obs_trigs, bigrs, bigPre, gamma3)
qbo_obs_trigrams
sum(unobs_backoff_bigrams$newprob) + sum(obs_backoff_bigrams$newprob)
alpha1
